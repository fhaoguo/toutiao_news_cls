{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a728f84",
   "metadata": {},
   "source": [
    "# 头条新闻分类NeZha With Head And Focal Loss With FGM PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e525ce",
   "metadata": {},
   "source": [
    "## 对抗训练方法\n",
    "### Fast Gradient Method(FGM)\n",
    "对于每个x:\n",
    "1. 计算x的前向loss, 反向传播得到梯度；\n",
    "2. 根据embeddign矩阵计算的梯度计算出r, 并加到当前embedding上，相当于x+r\n",
    "3. 计算x+r的前向loss, 反向传播得到梯度，然后累加到(1)的梯度上；\n",
    "4. 将embedding恢复为（1）时的embedding；\n",
    "5. 根据（3）的梯度对参数进行更新。\n",
    "\n",
    "### Projected Gradient Descent(PGD)\n",
    "FGM是一下子算出了对抗扰动，这样得到的扰动不一定是最优的。因此PGD进行了改进，多迭代了K/t次，慢慢找到最优的扰动\n",
    "对于每个x:\n",
    "1. 计算x的前向loss, 反向传播得到梯度；\n",
    "对于每步t：\n",
    "2. 根据embeddign矩阵计算的梯度计算出r, 并加到当前embedding上，相当于x+r；\n",
    "3. t如果不是最后一步，将梯度归0， 根据2的x+r计算前后向并得到梯度\n",
    "4. t是最后一步，恢复1的梯度，计算最后的x+r并将梯度累加到(1)上\n",
    "5. 将embedding恢复为（1）时的embedding\n",
    "6. 根据（4）的梯度对参数进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea76173",
   "metadata": {},
   "source": [
    "## 编写配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67510c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "config = {\n",
    "    'train_file_path': '../../../data/toutiao_news_cls/train.csv',\n",
    "    'test_file_path': '../../../data/toutiao_news_cls/test.csv',\n",
    "    'train_val_ratio': 0.1,  # 10%用作验证集\n",
    "    'head': 'cnn',\n",
    "    'model_path': '../../../pt/NeZha_model',\n",
    "    'batch_size': 16,      # batch 大小 16\n",
    "    'num_epochs': 1,      # 10次迭代\n",
    "    \n",
    "    'warmup_ratio': 0.1,   # warm, Focal Loss优化新增参数\n",
    "    \n",
    "    'eps': 0.1,            # 对抗模型需要的参数\n",
    "    'alpha': 0.3,          # pgd需要的参数\n",
    "    'adv': 'pgd',          # 对抗训练的方法\n",
    "    \n",
    "    'learning_rate': 2e-5, # 学习率\n",
    "    'logging_step': 300,   # 每跑300个batch记录一次\n",
    "    'seed': 2022           # 随机种子\n",
    "}\n",
    "\n",
    "config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu' # cpu&gpu\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    return seed\n",
    "\n",
    "seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e48bf8",
   "metadata": {},
   "source": [
    "## 数据预处理并编写DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6d34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa4ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert分词器\n",
    "bertTokenizer = BertTokenizer.from_pretrained(config['model_path'])\n",
    "# 重写分词器\n",
    "def tokenizer(sent):\n",
    "    inputs = bertTokenizer.encode_plus(sent, add_special_tokens=True, return_token_type_ids=True, return_attention_mask=True)\n",
    "    \n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78eb8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(config, mode='train'):\n",
    "    \n",
    "    data_df = pd.read_csv(config[f'{mode}_file_path'], sep=',')\n",
    "    LABEL, SENTENCE = 'label', 'sentence'\n",
    "    data_df['bert_encode'] = data_df[SENTENCE].apply(tokenizer)\n",
    "    data_df['input_ids'] = data_df['bert_encode'].apply(lambda s: s['input_ids'])\n",
    "    input_ids = np.array([[int(id_) for id_ in v] for v in data_df['input_ids'].values])\n",
    "    data_df['token_type_ids'] = data_df['bert_encode'].apply(lambda s: s['token_type_ids'])\n",
    "    token_type_ids = np.array([[int(id_) for id_ in v] for v in data_df['token_type_ids'].values])\n",
    "    data_df['attention_mask'] = data_df['bert_encode'].apply(lambda s: s['attention_mask'])\n",
    "    attention_mask = np.array([[int(id_) for id_ in v] for v in data_df['attention_mask'].values])\n",
    "\n",
    "    if mode == 'train':\n",
    "        labels = data_df[LABEL].values\n",
    "        \n",
    "        X_train, y_train = defaultdict(list), []\n",
    "        X_val, y_val = defaultdict(list), []\n",
    "        num_val = int(config['train_val_ratio'] * len(data_df))\n",
    "        \n",
    "        # shuffle ids\n",
    "        ids = np.random.choice(range(len(data_df)), size=len(data_df), replace=False)\n",
    "        train_ids = ids[num_val:]\n",
    "        val_ids = ids[:num_val]\n",
    "        \n",
    "        # get input_ids\n",
    "        X_train['input_ids'], y_train = input_ids[train_ids], labels[train_ids]\n",
    "        X_val['input_ids'], y_val = input_ids[val_ids], labels[val_ids]\n",
    "         # get token_type_ids\n",
    "        X_train['token_type_ids'] = token_type_ids[train_ids]\n",
    "        X_val['token_type_ids'] = token_type_ids[val_ids]\n",
    "        # get attention_mask\n",
    "        X_train['attention_mask'] = attention_mask[train_ids]\n",
    "        X_val['attention_mask'] = attention_mask[val_ids]\n",
    "     \n",
    "        # label \n",
    "        label2id = {label: i for i, label in enumerate(np.unique(y_train))}\n",
    "        id2label = {i: label for label, i in label2id.items()}\n",
    "        y_train = torch.tensor([label2id[y] for y in y_train], dtype=torch.long)\n",
    "        y_val = torch.tensor([label2id[y] for y in y_val], dtype=torch.long)\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, label2id, id2label\n",
    "\n",
    "    else:\n",
    "        X_test = defaultdict(list)\n",
    "        X_test['input_ids'] = input_ids\n",
    "        X_test['token_type_ids'] = token_type_ids\n",
    "        X_test['attention_mask'] = attention_mask\n",
    "        y_test = torch.zeros(len(data_df), dtype=torch.long)\n",
    "        \n",
    "        return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2929eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_val, y_val, label2id, id2label = read_data(config, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ee4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, y_test = read_data(config, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a4c71",
   "metadata": {},
   "source": [
    "#### Dataset提供数据集的封装，创建/继承Dataset必须实现:\n",
    "+ __len__: 整个数据集的长度\n",
    "+ __getitem__: 支持数据集索引的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa55be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TNEWSDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids' : self.x['input_ids'][idx],\n",
    "            'label' : self.y[idx],\n",
    "            'token_type_ids': self.x['token_type_ids'][idx],\n",
    "            'attention_mask': self.x['attention_mask'][idx]\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17714ed3",
   "metadata": {},
   "source": [
    "#### 使用DataLoader实现数据集的并行加载\n",
    "+ DataLoader提供一个可迭代对象，实现数据并行加载，从TNEWSDataset返回一个example，取多次，最后形成一个长度为batch_size的列表examples\n",
    "+ examples的格式：[dict1, dict2, ...]\n",
    "+ collate_fn()将examples中的数据合并为Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c16a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    input_ids_lst = []\n",
    "    labels = []\n",
    "    # ------ 与TextCNN不同的地方 ------\n",
    "    token_type_ids_lst = []\n",
    "    attention_mask_lst = []\n",
    "    # ------ 与TextCNN不同的地方 ------\n",
    "\n",
    "    for example in examples:\n",
    "        input_ids_lst.append(example['input_ids'])\n",
    "        labels.append(example['label'])\n",
    "        # ------ 与TextCNN不同的地方 ------\n",
    "        token_type_ids_lst.append(example['token_type_ids'])\n",
    "        attention_mask_lst.append(example['attention_mask'])\n",
    "        # ------ 与TextCNN不同的地方 ------\n",
    "        \n",
    "    # 计算input_ids_lst中最长的句子长度，对齐\n",
    "    max_length = max(len(input_ids) for input_ids in input_ids_lst)\n",
    "    # 定义一个Tensor\n",
    "    input_ids_tensor = torch.zeros((len(labels), max_length), dtype=torch.long)\n",
    "    # ------ 与TextCNN不同的地方 ------\n",
    "    token_type_ids_tensor = torch.zeros_like(input_ids_tensor)\n",
    "    attention_mask_tensor = torch.zeros_like(input_ids_tensor)\n",
    "    # ------ 与TextCNN不同的地方 ------\n",
    "    \n",
    "    for i, input_ids in enumerate(input_ids_lst):\n",
    "        seq_len = len(input_ids)\n",
    "        input_ids_tensor[i, :seq_len] = torch.tensor(input_ids, dtype=torch.long)\n",
    "        # ------ 与TextCNN不同的地方 ------\n",
    "        token_type_ids_tensor[i, :seq_len] = torch.tensor(token_type_ids_lst[i], dtype=torch.long)\n",
    "        attention_mask_tensor[i, :seq_len] = torch.tensor(attention_mask_lst[i], dtype=torch.long)\n",
    "        # ------ 与TextCNN不同的地方 ------\n",
    "        \n",
    "    return {\n",
    "        'input_ids': input_ids_tensor,\n",
    "        'labels': torch.tensor(labels, dtype=torch.long),\n",
    "        # ------ 与TextCNN不同的地方 ------\n",
    "        'token_type_ids': token_type_ids_tensor,\n",
    "        'attention_mask': attention_mask_tensor\n",
    "        # ------ 与TextCNN不同的地方 ------\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ac9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def build_dataloader(config):\n",
    "    X_train, y_train, X_val, y_val, label2id, id2label = read_data(config, mode='train')\n",
    "    X_test, y_test = read_data(config, mode='test')\n",
    "    \n",
    "    train_dataset = TNEWSDataset(X_train, y_train)\n",
    "    val_dataset = TNEWSDataset(X_val, y_val)\n",
    "    test_dataset = TNEWSDataset(X_test, y_test)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config['batch_size'], num_workers=0, shuffle=True, collate_fn=collate_fn)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=config['batch_size'], num_workers=0, shuffle=False, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=config['batch_size'], num_workers=0, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5def9409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fenghaoguo/opt/anaconda3/envs/ng/lib/python3.7/site-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  import sys\n",
      "/Users/fenghaoguo/opt/anaconda3/envs/ng/lib/python3.7/site-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if __name__ == '__main__':\n",
      "/Users/fenghaoguo/opt/anaconda3/envs/ng/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader, id2label = build_dataloader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8be30d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16 16 16\n",
      "{'input_ids': tensor([[ 101,  517, 1353, 2607, 6121, 1220,  518, 2972, 1139, 3859, 1930, 4276,\n",
      "         1391, 7883, 3952, 2767, 1070, 4374,  751, 7464, 8024,  872, 2582,  720,\n",
      "         4692, 8043,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 1920, 6825,  671, 3175, 7415, 1730, 3221, 2582,  720, 1355, 2245,\n",
      "         6629, 3341, 4638, 8043, 3300,  749, 6237, 1355, 2245, 1380, 4638,  720,\n",
      "         8043,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 4767, 7340, 1344, 5709, 3492, 3420, 4905, 2458, 6792, 5636, 2168,\n",
      "         6662,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 2809,  689, 5790, 2360, 4692, 6814, 3341, 8024,  872,  812, 3297,\n",
      "         1068, 2552, 4638, 1762, 6821,  749,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101,  100,  758, 1724,  100, 3309, 7313, 8024, 7946, 2255, 7349, 1140,\n",
      "         2773, 5279, 2573, 7667, 4638,  778, 4157,  102,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 6370,  749, 1139, 1744, 3952, 6762, 4873, 8024, 2844, 4212, 6814,\n",
      "         3309,  749, 8024, 6133, 1215, 6206, 1914,  719, 2897, 1168, 8024, 5543,\n",
      "         1343, 1408, 8043,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 4906, 2949, 4289, 3837, 7987, 6822, 1092, 8038, 1920,  816, 4289,\n",
      "         3837, 4638, 1158, 3173, 1355, 2245,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 1196, 5299, 3221, 1963,  862, 2875, 5470, 4028, 1447, 4638, 8043,\n",
      "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 2554, 1093, 3333, 8188, 1400, 4638, 1159,  704, 4495, 3889,  102,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 1290,  711, 6783,  749, 8711, 3403, 1114,  833, 2193, 5636, 2769,\n",
      "          812,  704, 1744,  821,  689, 1927, 1343,  784,  720, 8043,  102,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 3189, 3315, 3300, 3766, 3300, 5543, 1213,  794,  915, 5384, 3172,\n",
      "         2797,  704, 2843, 1726, 1266, 3175, 1724, 2270, 8043,  102,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 4343,  817, 6649, 6649,  679,  828,  862, 3198, 5543, 1168, 2419,\n",
      "         8043,  143, 5500, 3297, 5283, 2248, 2153, 5500, 1290, 5320, 5500,  819,\n",
      "         5357,  862, 6834, 1158, 3173, 7770, 8043,  102,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 2408, 2336, 2608, 1920, 4638, 6948, 3255, 3297, 6818,  711,  784,\n",
      "          720,  671, 4684, 3766, 3300, 6822, 1057, 3683, 6612, 1399, 1296, 8024,\n",
      "         3221, 1358,  839, 6820, 3221,  784,  720, 1166, 4638, 1333, 1728, 8043,\n",
      "          102],\n",
      "        [ 101,  677, 5468, 8038,  671, 2428, 3217, 7599,  671, 2428, 2687, 8024,\n",
      "         7942, 5709, 5862, 2226, 8024, 1963,  862, 2190,  678, 5468, 8043,  102,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 2349, 5838, 4294, 8038, 3187,  782, 7730, 7724, 7585, 6208,  772,\n",
      "          689, 3419, 2229,  924, 7372, 1062, 1385, 2199, 2689, 1355, 1737, 7410,\n",
      "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0],\n",
      "        [ 101, 1920, 2349, 7944,  697, 4413, 3215, 6158, 1398,  671, 2157,  936,\n",
      "          727, 6956, 4681,  677, 8013,  122,  783, 3616, 3766, 1168, 2797, 2218,\n",
      "         1762, 2682, 2582,  720, 5709, 8013,  102,    0,    0,    0,    0,    0,\n",
      "            0]]), 'labels': tensor([14,  5, 13,  4,  1, 10,  8,  2,  7,  8,  9, 13,  3,  1,  8,  3]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(len(batch['input_ids']), len(batch['labels']), len(batch['token_type_ids']), len(batch['attention_mask']))\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32772a",
   "metadata": {},
   "source": [
    "## 训练验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10cc4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeZha + head part2\n",
    "from NeZha import *\n",
    "from extra_loss import *\n",
    "\n",
    "class NeZhaForTNEWS(NeZhaPreTrainedModel):\n",
    "    # classifier -- head\n",
    "    def __init__(self, config, model_path, classifier):\n",
    "        super(NeZhaForTNEWS, self).__init__(config)\n",
    "\n",
    "        self.bert = NeZhaModel.from_pretrained(model_path, config=config)\n",
    "        self.classifier = classifier  # head\n",
    "        self.config = config  # Focal Loss 优化新增代码\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor=None,\n",
    "                token_type_ids: torch.Tensor=None,\n",
    "                attention_mask: torch.Tensor=None,\n",
    "                labels: torch.Tensor=None):\n",
    "\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask, \n",
    "                            token_type_ids=token_type_ids)\n",
    "        \n",
    "        hidden_states = outputs[2]\n",
    "        \n",
    "        logits = self.classifier(hidden_states, input_ids)\n",
    "        \n",
    "        outputs =(logits, )\n",
    "        # 使用训练集、验证集\n",
    "        if labels is not None:\n",
    "            # Focal Loss 损失计算优化代码\n",
    "            # loss_fct = nn.CrossEntropyLoss()\n",
    "            loss_fct = FocalLoss(num_classes=self.config.num_labels)\n",
    "            loss = loss_fct(logits, labels.view(-1))\n",
    "            outputs =(loss, ) + outputs\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc966f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "class ConvClassifier(nn.Module):\n",
    "    '''\n",
    "    CNN + global max pool\n",
    "    '''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels=config.hidden_size, out_channels=config.hidden_size, kernel_size=3)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.fc = nn.Linear(config.hidden_size, config.num_labels)\n",
    "    \n",
    "    def forward(self, hidden_states, input_ids):\n",
    "        hidden_states = self.dropout(hidden_states[-1])#只取出最后一层\n",
    "        # hidden_states shape (bs, seq_len, hidden_size) -> (bs, hidden_size, seq_len) \n",
    "        hidden_states = hidden_states.permute(0, 2, 1)\n",
    "        out = F.relu(self.conv(hidden_states))\n",
    "        \n",
    "        # out (bs, hidden_size_out, seq_len_out)\n",
    "        # out (bs, hidden_size, 1)\n",
    "        # out (bs, hidden_size)\n",
    "        out = self.global_max_pool(out).squeeze(dim=2)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1006164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_path, config, head):\n",
    "    heads = {\n",
    "        'cnn':ConvClassifier\n",
    "    }\n",
    "    assert head in heads, \"@_@:head must have been implemented!\"\n",
    "    print(f'>>>You are using {head} head ...')\n",
    "    model = NeZhaForTNEWS(config, model_path, heads[head](config))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e2a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluation(config, model, val_dataloader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    val_loss = 0.\n",
    "    val_iterator = tqdm(val_dataloader, desc='Evaluation...', total=len(val_dataloader))\n",
    "    with torch.no_grad():\n",
    "        for batch in val_iterator:\n",
    "            labels.append(batch['labels'])\n",
    "            batch = {item:value.to(config['device']) for item, value in batch.items()}\n",
    "            \n",
    "            # val output (loss, out)\n",
    "            loss, logits = model(**batch)[:2]\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            preds.append(logits.argmax(dim=-1).detach().cpu())\n",
    "            \n",
    "    avg_val_loss = val_loss/len(val_dataloader)\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    \n",
    "    precision = precision_score(labels, preds, average='macro')\n",
    "    recall = recall_score(labels, preds, average='macro')\n",
    "    f1 =f1_score(labels, preds, average='macro')\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    \n",
    "    return avg_val_loss, f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6614940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeZha model + Head train\n",
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from tqdm import trange\n",
    "\n",
    "from extra_optim import *\n",
    "from extra_fgm import *\n",
    "from extra_pgd import *\n",
    "\n",
    "def train(config, train_dataloader, val_dataloader, model):\n",
    "\n",
    "    optimizer_grouped_parameters = model.parameters()\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=config['learning_rate'])\n",
    "    optimizer = Lookahead(optimizer, 5, 1)\n",
    "    total_steps = config['num_epochs'] * len(train_dataloader)\n",
    "    lr_scheduler = WarmupLinearSchedule(optimizer, \n",
    "                                        warmup_steps=int(config['warmup_ratio'] * total_steps),\n",
    "                                        t_total=total_steps)\n",
    "    \n",
    "    model.to(config['device'])\n",
    "    \n",
    "    # --- 对抗训练优化代码\n",
    "    if config['adv'] == 'fgm':\n",
    "        fgm = FGM(model)\n",
    "    else:\n",
    "        pgd = PGD(model)\n",
    "        K = 3\n",
    "    # --- 对抗训练优化代码\n",
    "    \n",
    "    epoches_iterator = trange(config['num_epochs'])\n",
    "    global_steps = 0\n",
    "    train_loss = 0.\n",
    "    logging_loss = 0.\n",
    "    \n",
    "    best_f1 = 0.\n",
    "    best_precision = 0.\n",
    "    best_recall = 0.\n",
    "    best_accuracy = 0.\n",
    "    \n",
    "    for epoch in epoches_iterator:\n",
    "        train_iterator = tqdm(train_dataloader, desc='Training', total=len(train_dataloader))\n",
    "        model.train()\n",
    "        for batch in train_iterator:\n",
    "            batch = {item:value.to(config['device']) for item, value in batch.items()}\n",
    "            \n",
    "            # train output (loss, out)\n",
    "            loss = model(**batch)[0]  #计算x的前向loss\n",
    "            \n",
    "            model.zero_grad()  # 模型参数梯度清零\n",
    "            loss.backward()  # 反向传播得到梯度\n",
    "            \n",
    "            # --- 对抗训练优化代码\n",
    "            if config['adv'] == 'fgm':\n",
    "                # 计算x+r的前向loss, 反向传播得到梯度，然后累加到(1)的梯度上；\n",
    "                fgm.attack(epsilon=config['eps'])\n",
    "                # 计算x+r的前向loss\n",
    "                loss_adv = model(**batch)[0]\n",
    "                # 反向传播得到梯度，然后累加到(1)的梯度上；\n",
    "                loss_adv.backward()\n",
    "                #将embedding恢复为（1）时的embedding；\n",
    "                fgm.restore()\n",
    "            else:\n",
    "                pgd.backup_grad()\n",
    "                for t in range(K):\n",
    "                    pgd.attack(epsilon=config['eps'], alpha=config['alpha'], is_first_attack=(t == 0))\n",
    "                    if t != K - 1:\n",
    "                        model.zero_grad()\n",
    "                    else:\n",
    "                        pgd.restore_grad()\n",
    "                    loss_adv = model(**batch)[0]\n",
    "                    loss_adv.backward()\n",
    "                pgd.restore()\n",
    "            # --- 对抗训练优化代码\n",
    "            \n",
    "            optimizer.step()  # 更新参数\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            train_loss += loss.item()  # 叠加loss\n",
    "            global_steps += 1\n",
    "            \n",
    "            if global_steps % config['logging_step'] == 0:\n",
    "                print_train_loss = (train_loss - logging_loss) / config['logging_step']\n",
    "                logging_loss = train_loss\n",
    "                avg_val_loss, f1, precision, recall, accuracy = evaluation(config, model, val_dataloader)\n",
    "                \n",
    "                if best_f1 < f1:\n",
    "                    best_f1 = f1\n",
    "                    best_precision = precision\n",
    "                    best_recall = recall\n",
    "                    best_accuracy = accuracy\n",
    "                    print_log = f'''>>> training loss: {print_train_loss: .4f}, valid loss: {avg_val_loss: .4f}\\n\n",
    "                            valid f1 score: {f1: .4f}, valid precision score: {precision: .4f},\n",
    "                            valid recall score: {recall: .4f}, valid accuracy score: {accuracy: .4f}'''\n",
    "                    print(print_log)\n",
    "                    model.save_pretrained(os.path.join('../../../pt_tmp/cls/nezha_head_fl_fgm_pgd', config['adv']))\n",
    "                    \n",
    "                model.train()\n",
    "                \n",
    "    return best_f1, best_precision, best_recall, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf9e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>You are using cnn head ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../../pt/NeZha_model were not used when initializing NeZhaModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing NeZhaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NeZhaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of NeZhaModel were not initialized from the model checkpoint at ../../../pt/NeZha_model and are newly initialized: ['bert.encoder.layer.1.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.6.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.10.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.0.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.3.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.7.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.5.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.4.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.11.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.9.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.8.attention.self.relative_positions_encoding.positions_encoding', 'bert.encoder.layer.2.attention.self.relative_positions_encoding.positions_encoding']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/fenghaoguo/opt/anaconda3/envs/ng/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|                                                                                                                                                              | 0/1 [00:00<?, ?it/s]\n",
      "Training:   0%|                                                                                                                                                 | 0/3002 [00:00<?, ?it/s]\u001b[A/Users/fenghaoguo/opt/anaconda3/envs/ng/lib/python3.7/site-packages/transformers/modeling_utils.py:700: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
      "\n",
      "Training:   0%|                                                                                                                                      | 1/3002 [00:15<13:13:46, 15.87s/it]\u001b[A\n",
      "Training:   0%|                                                                                                                                      | 2/3002 [00:32<13:32:10, 16.24s/it]\u001b[A\n",
      "Training:   0%|▏                                                                                                                                     | 3/3002 [00:46<12:33:11, 15.07s/it]\u001b[A\n",
      "Training:   0%|▏                                                                                                                                     | 4/3002 [01:02<12:55:56, 15.53s/it]\u001b[A\n",
      "Training:   0%|▏                                                                                                                                     | 5/3002 [01:15<12:11:51, 14.65s/it]\u001b[A\n",
      "Training:   0%|▎                                                                                                                                     | 6/3002 [01:29<12:06:58, 14.56s/it]\u001b[A\n",
      "Training:   0%|▎                                                                                                                                     | 7/3002 [01:43<11:50:48, 14.24s/it]\u001b[A\n",
      "Training:   0%|▎                                                                                                                                     | 8/3002 [01:57<11:42:46, 14.08s/it]\u001b[A\n",
      "Training:   0%|▍                                                                                                                                     | 9/3002 [02:10<11:36:22, 13.96s/it]\u001b[A\n",
      "Training:   0%|▍                                                                                                                                    | 10/3002 [02:24<11:39:09, 14.02s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# 首次运行代码\n",
    "bert_config = NeZhaConfig.from_pretrained(config['model_path'])\n",
    "bert_config.output_hidden_states = True\n",
    "bert_config.num_labels = len(id2label)\n",
    "model = build_model(config['model_path'], bert_config, config['head'])\n",
    "f1, precision, recall, accuracy = train(config, train_dataloader, val_dataloader, model)\n",
    "print_log = f'''valid f1 score: {f1: .4f}, valid precision score: {precision: .4f},\n",
    "                valid recall score: {recall: .4f}, valid accuracy score: {accuracy: .4f}'''\n",
    "print(print_log)\n",
    "\n",
    "# 迭代训练代码\n",
    "# bert_config = BertConfig.from_pretrained('../../../pt_tmp/cls/nezha_head_fl_fgm_pgd')\n",
    "# bert_config.output_hidden_states = True\n",
    "# bert_config.num_labels = len(id2label)\n",
    "# model = build_model('../../../pt_tmp/cls/nezha_head_fl_fgm_pgd', bert_config, config['head'])\n",
    "# f1, precision, recall, accuracy = train(config, train_dataloader, val_dataloader, model)\n",
    "# print_log = f'''valid f1 score: {f1: .4f}, valid precision score: {precision: .4f},\n",
    "#                 valid recall score: {recall: .4f}, valid accuracy score: {accuracy: .4f}'''\n",
    "# print(print_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c2a95",
   "metadata": {},
   "source": [
    "## 预测并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47176d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(config, id2label, model, test_dataloader):\n",
    "    test_iterator = tqdm(test_dataloader, desc='Testing', total=len(test_dataloader))\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_iterator:\n",
    "            batch = {item: value.to(config['device']) for item, value in batch.items()}\n",
    "\n",
    "            logits = model(**batch)[1]\n",
    "            test_preds.append(logits.argmax(dim=-1).detach().cpu())\n",
    "            \n",
    "    test_preds = torch.cat(test_preds, dim=0).numpy()\n",
    "    test_preds = [id2label[id_] for id_ in test_preds]\n",
    "        \n",
    "    test_df = pd.read_csv(config['test_file_path'], sep=',')\n",
    "    # test_df.insert(1, column=['label_pred'], value=test_preds)\n",
    "    test_df['label_pred'] = test_preds\n",
    "    # test_df.drop(columns=['sentence'], inplace=True)\n",
    "    test_df.to_csv('submission.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60fde8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████| 625/625 [10:44<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "predict(config, id2label, best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bf771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(config['test_file_path'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4364da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(config['train_file_path'], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d665174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>label_desc</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>news_edu</td>\n",
       "      <td>上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>news_finance</td>\n",
       "      <td>商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>news_house</td>\n",
       "      <td>通过中介公司买了二手房，首付都付了，现在卖家不想卖了。怎么处理？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>news_travel</td>\n",
       "      <td>2018年去俄罗斯看世界杯得花多少钱？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>news_tech</td>\n",
       "      <td>剃须刀的个性革新，雷明登天猫定制版新品首发</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>news_sports</td>\n",
       "      <td>再次证明了“无敌是多么寂寞”——逆天的中国乒乓球队！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>109</td>\n",
       "      <td>news_tech</td>\n",
       "      <td>三农盾SACC-全球首个推出：互联网+区块链+农产品的电商平台</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>news_game</td>\n",
       "      <td>重做or新英雄？其实重做对暴雪来说同样重要</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>103</td>\n",
       "      <td>news_sports</td>\n",
       "      <td>如何在商业活动中不受人欺骗？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>101</td>\n",
       "      <td>news_culture</td>\n",
       "      <td>87版红楼梦最温柔的四个丫鬟，娶谁都是一生的福气</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label    label_desc                                        sentence\n",
       "0   0    108      news_edu    上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？\n",
       "1   1    104  news_finance  商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告\n",
       "2   2    106    news_house                通过中介公司买了二手房，首付都付了，现在卖家不想卖了。怎么处理？\n",
       "3   3    112   news_travel                             2018年去俄罗斯看世界杯得花多少钱？\n",
       "4   4    109     news_tech                           剃须刀的个性革新，雷明登天猫定制版新品首发\n",
       "5   5    103   news_sports                      再次证明了“无敌是多么寂寞”——逆天的中国乒乓球队！\n",
       "6   6    109     news_tech                 三农盾SACC-全球首个推出：互联网+区块链+农产品的电商平台\n",
       "7   7    116     news_game                           重做or新英雄？其实重做对暴雪来说同样重要\n",
       "8   8    103   news_sports                                  如何在商业活动中不受人欺骗？\n",
       "9   9    101  news_culture                        87版红楼梦最温柔的四个丫鬟，娶谁都是一生的福气"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e7757f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108, 104, 106, 112, 109, 103, 116, 101, 107, 100, 102, 110, 115,\n",
       "       113, 114])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321e381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
